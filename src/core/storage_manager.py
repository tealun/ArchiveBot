"""
Storage manager module
Manages content storage across different providers
"""

import logging
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime
from telegram import Message

from ..storage.database import DatabaseStorage
from ..storage.telegram import TelegramStorage
from ..core.tag_manager import TagManager
from ..core.analyzer import ContentAnalyzer
from ..utils.helpers import format_datetime, format_file_size
from ..utils.i18n import get_i18n
from ..utils.config import get_config
from ..utils.constants import (
    TELEGRAM_MAX_SIZE,
    STORAGE_DATABASE,
    STORAGE_TELEGRAM,
    STORAGE_REFERENCE
)

logger = logging.getLogger(__name__)


class StorageManager:
    """
    Manages content storage strategy and execution
    """
    
    def __init__(
        self, 
        db_storage: DatabaseStorage, 
        tag_manager: TagManager,
        telegram_storage: Optional[TelegramStorage] = None
    ):
        """
        Initialize storage manager
        
        Args:
            db_storage: DatabaseStorage instance
            tag_manager: TagManager instance
            telegram_storage: TelegramStorage instance (optional)
        """
        self.db_storage = db_storage
        self.tag_manager = tag_manager
        self.telegram_storage = telegram_storage
        self.ai_cache = None  # Will be set by main.py
        self.i18n = get_i18n()
    
    def set_ai_cache(self, ai_cache):
        """Set AI data cache instance (called after initialization)"""
        self.ai_cache = ai_cache
    
    def _invalidate_ai_cache(self):
        """å¤±æ•ˆAIæ•°æ®ç¼“å­˜"""
        if self.ai_cache:
            self.ai_cache.invalidate('statistics', 'recent_samples', 'tag_analysis')
            logger.debug("AI cache invalidated")
    
    async def batch_archive_content(self, messages: list, analyses: list, source_info: Optional[Dict[str, Any]] = None, is_batch_forwarded: bool = False, progress_callback=None) -> list:
        """
        æ‰¹é‡å½’æ¡£å†…å®¹ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å­˜å‚¨åˆ°Telegramé¢‘é“ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            analyses: åˆ†æç»“æœåˆ—è¡¨
            source_info: æ‰¹æ¬¡æ¥æºä¿¡æ¯ï¼ˆä»batchä¸­æå–ï¼‰
            is_batch_forwarded: æ‰¹æ¬¡æ˜¯å¦ä¸ºè½¬å‘æ¶ˆæ¯
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, stage)
            
        Returns:
            [(success, message, archive_id), ...]
        """
        if len(messages) != len(analyses):
            logger.error(f"Messages and analyses count mismatch: {len(messages)} vs {len(analyses)}")
            return [(False, "Internal error", None) for _ in messages]
        
        results = []
        total = len(messages)
        
        # æ”¶é›†éœ€è¦å­˜å‚¨åˆ°Telegramçš„æ–‡ä»¶
        telegram_indices = []
        telegram_metadata_list = []
        
        # å¯¹äºæ‰¹æ¬¡æ¶ˆæ¯ï¼Œç¡®å®šæ˜¯å¦ä¸ºç›´å‘ï¼ˆæ‰¹æ¬¡ä¸­æ— è½¬å‘ä¿¡æ¯åˆ™è®¤ä¸ºæ˜¯ç›´å‘ï¼‰
        is_direct_send = not is_batch_forwarded
        
        for i, (message, analysis) in enumerate(zip(messages, analyses)):
            content_type = analysis.get('content_type')
            storage_type = self._determine_storage_type(content_type, analysis.get('file_size'))
            
            if storage_type == STORAGE_TELEGRAM and self.telegram_storage:
                telegram_indices.append(i)
                
                # æ”¶é›†æ ‡ç­¾ç”¨äºé¢‘é“é€‰æ‹©
                collected_tags = []
                collected_tags.extend(analysis.get('hashtags', []))
                collected_tags.extend(analysis.get('tags', []))
                
                # æ ¹æ®è§„åˆ™ç¡®å®šé¢‘é“
                target_channel_id = self._determine_channel_id(
                    content_type=content_type,
                    tags=collected_tags,
                    source_info=source_info,
                    is_direct_send=is_direct_send
                )
                
                metadata = {
                    'file_id': analysis.get('file_id'),
                    'content_type': content_type,
                    'caption': analysis.get('content') or analysis.get('title'),  # ä½¿ç”¨contentï¼ˆå«æ‰¹æ³¨ï¼‰ï¼Œå›é€€åˆ°title
                    'file_size': analysis.get('file_size', 0)
                }
                
                # å¦‚æœç¡®å®šäº†ç‰¹å®šé¢‘é“ï¼Œæ·»åŠ override
                if target_channel_id:
                    metadata['override_channel_id'] = target_channel_id
                
                telegram_metadata_list.append(metadata)
        
        # æ‰¹é‡å­˜å‚¨åˆ°Telegramï¼ˆå¦‚æœæœ‰ï¼‰
        telegram_storage_paths = []
        if telegram_indices:
            logger.info(f"Batch storing {len(telegram_indices)} files to Telegram channel")
            telegram_storage_paths = await self.telegram_storage.batch_store(telegram_metadata_list)
        
        # é€ä¸ªåˆ›å»ºæ•°æ®åº“è®°å½•ï¼ˆå¸¦è¿›åº¦æ›´æ–°ï¼‰
        for i, (message, analysis) in enumerate(zip(messages, analyses)):
            try:
                content_type = analysis.get('content_type')
                
                if content_type == 'error':
                    results.append((False, self.i18n.t('archive_failed', error=analysis.get('error', 'Unknown')), None))
                    continue
                
                # Determine storage
                storage_type = self._determine_storage_type(content_type, analysis.get('file_size'))
                storage_path = None
                storage_provider = None
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡å­˜å‚¨çš„
                if i in telegram_indices:
                    idx_in_batch = telegram_indices.index(i)
                    storage_path = telegram_storage_paths[idx_in_batch]
                    if storage_path:
                        storage_provider = 'telegram_channel'
                    else:
                        storage_type = STORAGE_REFERENCE
                        logger.warning(f"Batch store failed for item {i}, downgraded to reference")
                
                # Create archive entry
                message = messages[i] if i < len(messages) else None
                media_group_id = message.media_group_id if message and hasattr(message, 'media_group_id') else None
                
                archive_id = self.db_storage.create_archive(
                    content_type=content_type,
                    storage_type=storage_type,
                    title=analysis.get('title'),
                    content=analysis.get('content'),
                    file_id=analysis.get('file_id'),
                    storage_provider=storage_provider,
                    storage_path=storage_path,
                    file_size=analysis.get('file_size'),
                    source=analysis.get('source'),
                    metadata={
                        'file_name': analysis.get('file_name'),
                        'mime_type': analysis.get('mime_type'),
                        'url': analysis.get('url'),
                    },
                    ai_summary=analysis.get('ai_summary'),
                    ai_key_points=analysis.get('ai_key_points'),
                    ai_category=analysis.get('ai_category'),
                    media_group_id=media_group_id
                )
                
                # Generate and add tags
                all_tags = []
                
                # Auto tags
                auto_tags = self.tag_manager.generate_auto_tags(content_type)
                if auto_tags:
                    self.tag_manager.add_tags_to_archive(archive_id, auto_tags, 'auto')
                    all_tags.extend(auto_tags)
                
                # Manual tags from hashtags
                manual_tags = analysis.get('hashtags', [])
                if manual_tags:
                    self.tag_manager.add_tags_to_archive(archive_id, manual_tags, 'manual')
                    all_tags.extend(manual_tags)
                
                # AI tags
                ai_tags = analysis.get('tags', [])
                if ai_tags:
                    unique_ai_tags = [tag for tag in ai_tags if tag not in all_tags]
                    if unique_ai_tags:
                        self.tag_manager.add_tags_to_archive(archive_id, unique_ai_tags, 'ai')
                        all_tags.extend(unique_ai_tags)
                
                # Success message (ä½¿ç”¨MessageBuilderç»Ÿä¸€æ„å»º)
                from ..utils.message_builder import MessageBuilder
                
                # è·å–botå®ä¾‹ï¼ˆä» telegram_storage ä¸­è·å–ï¼‰
                bot = self.telegram_storage.bot if self.telegram_storage else None
                
                success_msg = await MessageBuilder.build_archive_success_message(
                    archive_data={
                        'title': analysis.get('title'),
                        'content': analysis.get('content'),
                        'caption': analysis.get('caption'),  # æ·»åŠ caption
                        'content_type': content_type,
                        'file_size': analysis.get('file_size', 0),
                        'tags': all_tags,
                        'storage_type': storage_type,
                        'storage_provider': storage_provider,
                        'storage_path': storage_path,
                        'source': analysis.get('source', 'ç›´æ¥å‘é€'),
                        'ai_title': analysis.get('ai_title'),  # æ·»åŠ AIæ ‡é¢˜
                        'ai_summary': analysis.get('ai_summary'),
                        'ai_category': analysis.get('ai_category'),
                        'ai_key_points': analysis.get('ai_key_points', [])
                    },
                    i18n=self.i18n,
                    include_ai_info=True,
                    bot=bot
                )
                
                results.append((True, success_msg, archive_id))
                
                # æ›´æ–°è¿›åº¦
                if progress_callback and (i + 1) % max(1, total // 20) == 0:
                    await progress_callback(i + 1, total, "å­˜å‚¨åˆ°é¢‘é“")
                
            except Exception as e:
                logger.error(f"Error in batch archive item {i}: {e}", exc_info=True)
                results.append((False, str(e), None))
        
        logger.info(f"Batch archived {sum(1 for s, _, _ in results if s)}/{len(results)} items")
        return results
    
    async def archive_content(
        self,
        message: Message,
        analysis: Dict[str, Any],
        source_info: Dict[str, Any] = None,
        is_direct_send: bool = False
    ) -> Tuple[bool, str]:
        """
        Archive content based on analysis
        
        Args:
            message: Telegram message object
            analysis: Content analysis result
            source_info: æ¶ˆæ¯æ¥æºä¿¡æ¯ {'name': str, 'id': int, 'type': str}
            is_direct_send: æ˜¯å¦ä¸ºä¸ªäººç›´æ¥å‘é€ï¼ˆéè½¬å‘ï¼‰
            
        Returns:
            Tuple of (success, message)
        """
        try:
            content_type = analysis.get('content_type')
            
            if content_type == 'error':
                return False, self.i18n.t('archive_failed', error=analysis.get('error', 'Unknown'))
            
            # Determine storage type
            storage_type = self._determine_storage_type(content_type, analysis.get('file_size'))
            logger.info(f"Determined storage type: {storage_type} for {content_type} (size: {analysis.get('file_size')})")
            
            # æ”¶é›†æ ‡ç­¾ï¼ˆç”¨äºé¢‘é“é€‰æ‹©ï¼‰
            collected_tags = []
            collected_tags.extend(analysis.get('hashtags', []))
            collected_tags.extend(analysis.get('tags', []))
            
            # Store file if needed
            storage_path = None
            storage_provider = None
            
            # å…ˆåˆ›å»ºarchiveè®°å½•ï¼ˆè·å–archive_idç”¨äºç”ŸæˆæŒ‰é’®ï¼‰
            archive_id = self.db_storage.create_archive(
                content_type=content_type,
                storage_type=storage_type,
                title=analysis.get('title'),
                content=analysis.get('content'),
                file_id=analysis.get('file_id'),
                storage_provider=storage_provider,
                storage_path=storage_path or '',  # ä¸´æ—¶ä¸ºç©ºï¼Œåé¢ä¼šæ›´æ–°
                file_size=analysis.get('file_size'),
                source=analysis.get('source'),
                metadata={
                    'file_name': analysis.get('file_name'),
                    'mime_type': analysis.get('mime_type'),
                    'url': analysis.get('url'),
                },
                ai_summary=analysis.get('ai_summary'),
                ai_key_points=analysis.get('ai_key_points'),
                ai_category=analysis.get('ai_category'),
                media_group_id=message.media_group_id if hasattr(message, 'media_group_id') else None
            )
            
            # å¸¸è§„å­˜å‚¨é€»è¾‘ï¼ˆä¼ é€’archive_idç”¨äºç”ŸæˆæŒ‰é’®ï¼‰
            if storage_type == STORAGE_TELEGRAM and self.telegram_storage and not storage_path:
                # Store to Telegram channel
                try:
                    storage_path = await self._store_to_telegram(
                        analysis,
                        tags=collected_tags,
                        source_info=source_info,
                        is_direct_send=is_direct_send,
                        archive_id=archive_id  # ä¼ é€’archive_idç”¨äºç”ŸæˆæŒ‰é’®
                    )
                    if storage_path:
                        storage_provider = 'telegram_channel'
                        logger.info(f"File stored to Telegram: {storage_path}")
                        # æ›´æ–°storage_path
                        self.db_storage.db.execute(
                            "UPDATE archives SET storage_path = ?, storage_provider = ? WHERE id = ?",
                            (storage_path, storage_provider, archive_id)
                        )
                        self.db_storage.db.commit()
                    else:
                        # Fallback to reference only
                        storage_type = STORAGE_REFERENCE
                        logger.warning(f"Failed to store to Telegram, downgraded to reference: {content_type}")
                        self.db_storage.db.execute(
                            "UPDATE archives SET storage_type = ? WHERE id = ?",
                            (storage_type, archive_id)
                        )
                        self.db_storage.db.commit()
                except Exception as e:
                    logger.error(f"Error storing to Telegram: {e}", exc_info=True)
                    storage_type = STORAGE_REFERENCE
                    logger.warning(f"Exception during Telegram storage, downgraded to reference: {content_type}")
                    self.db_storage.db.execute(
                        "UPDATE archives SET storage_type = ? WHERE id = ?",
                        (storage_type, archive_id)
                    )
                    self.db_storage.db.commit()
            
            # ç‰¹æ®Šå¤„ç†ï¼šlinkç±»å‹å¦‚æœæœ‰PDFï¼Œå­˜å‚¨PDFåˆ°documenté¢‘é“
            if content_type == 'link' and analysis.get('web_archive_pdf') and not storage_path:
                try:
                    pdf_path = await self._store_link_pdf(
                        analysis=analysis,
                        tags=collected_tags,
                        source_info=source_info,
                        is_direct_send=is_direct_send,
                        archive_id=archive_id
                    )
                    
                    if pdf_path:
                        storage_path = pdf_path
                        storage_provider = 'telegram_channel_pdf'
                        storage_type = STORAGE_TELEGRAM
                        logger.info(f"Link PDF stored to document channel: {pdf_path}")
                        # æ›´æ–°storage_path
                        self.db_storage.db.execute(
                            "UPDATE archives SET storage_path = ?, storage_provider = ?, storage_type = ? WHERE id = ?",
                            (storage_path, storage_provider, storage_type, archive_id)
                        )
                        self.db_storage.db.commit()
                    else:
                        logger.warning("Failed to store link PDF, will use text storage")
                        
                except Exception as e:
                    logger.error(f"Error storing link PDF: {e}", exc_info=True)
            
            # è§¦å‘AIæ•°æ®ç¼“å­˜å¤±æ•ˆï¼ˆæ–°å½’æ¡£æ·»åŠ ï¼‰
            self._invalidate_ai_cache()
            
            # Generate and add tags
            all_tags = []
            
            # Auto tags based on content type
            auto_tags = self.tag_manager.generate_auto_tags(content_type)
            if auto_tags:
                self.tag_manager.add_tags_to_archive(archive_id, auto_tags, 'auto')
                all_tags.extend(auto_tags)
            
            # Manual tags from hashtags
            manual_tags = analysis.get('hashtags', [])
            if manual_tags:
                self.tag_manager.add_tags_to_archive(archive_id, manual_tags, 'manual')
                all_tags.extend(manual_tags)
            
            # AI tags from analysis (ä¿®å¤ï¼šä»'tags'å­—æ®µè·å–AIç”Ÿæˆçš„æ ‡ç­¾)
            ai_tags = analysis.get('tags', [])
            if ai_tags:
                # è¿‡æ»¤æ‰å·²ç»æ·»åŠ çš„autoå’Œmanualæ ‡ç­¾
                unique_ai_tags = [tag for tag in ai_tags if tag not in all_tags]
                if unique_ai_tags:
                    self.tag_manager.add_tags_to_archive(archive_id, unique_ai_tags, 'ai')
                    all_tags.extend(unique_ai_tags)
                    logger.info(f"Added AI tags: {unique_ai_tags}")
            
            # Format success message (ä½¿ç”¨MessageBuilderç»Ÿä¸€æ„å»º)
            from ..utils.message_builder import MessageBuilder
            
            # è·å–botå®ä¾‹ï¼ˆä» telegram_storage ä¸­è·å–ï¼‰
            bot = self.telegram_storage.bot if self.telegram_storage else None
            
            success_msg = await MessageBuilder.build_archive_success_message(
                archive_data={
                    'title': analysis.get('title'),
                    'content': analysis.get('content'),
                    'caption': analysis.get('caption'),  # æ·»åŠ caption
                    'content_type': content_type,
                    'file_size': analysis.get('file_size', 0),
                    'tags': all_tags,
                    'storage_type': storage_type,
                    'storage_provider': storage_provider,
                    'storage_path': storage_path,
                    'source': analysis.get('source', 'ç›´æ¥å‘é€'),
                    'ai_title': analysis.get('ai_title'),  # æ·»åŠ AIæ ‡é¢˜
                    'ai_summary': analysis.get('ai_summary'),
                    'ai_category': analysis.get('ai_category'),
                    'ai_key_points': analysis.get('ai_key_points', [])
                },
                i18n=self.i18n,
                include_ai_info=True,
                bot=bot
            )
            
            logger.info(f"Successfully archived content: archive_id={archive_id}")
            return True, success_msg, archive_id
            
        except Exception as e:
            logger.error(f"Error archiving content: {e}", exc_info=True)
            return False, self.i18n.t('archive_failed', error=str(e)), None
    
    def _determine_channel_id(
        self, 
        content_type: str, 
        tags: List[str] = None,
        source_info: Dict[str, Any] = None,
        is_direct_send: bool = False
    ) -> Optional[int]:
        """
        æ ¹æ®å¤šç§è§„åˆ™ç¡®å®šå­˜å‚¨é¢‘é“IDï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
        
        ä¼˜å…ˆçº§:
        1. æ ‡ç­¾åŒ¹é… (tag_mapping)
        2. æ¥æºåŒ¹é… (source_mapping)
        3. ä¸ªäººç›´å‘é…ç½® (direct_send)
        4. å†…å®¹ç±»å‹æ˜ å°„ (type_mapping)
        5. é»˜è®¤é¢‘é“ (default)
        
        Args:
            content_type: å†…å®¹ç±»å‹
            tags: æ ‡ç­¾åˆ—è¡¨
            source_info: æ¥æºä¿¡æ¯ {'name': str, 'id': int, 'type': str}
            is_direct_send: æ˜¯å¦ä¸ºä¸ªäººç›´æ¥å‘é€
            
        Returns:
            é¢‘é“IDæˆ–None
        """
        config = get_config()
        
        # ä¼˜å…ˆçº§1: æ ‡ç­¾åŒ¹é…
        if tags:
            tag_mapping = config.get('storage.telegram.tag_mapping', [])
            if tag_mapping:
                for mapping in tag_mapping:
                    mapping_tags = mapping.get('tags', [])
                    channel_id = mapping.get('channel_id')
                    if channel_id and any(tag in mapping_tags for tag in tags):
                        logger.info(f"Channel determined by tag mapping: {channel_id} (matched tags: {[t for t in tags if t in mapping_tags]})")
                        return channel_id
        
        # ä¼˜å…ˆçº§2: æ¥æºåŒ¹é…
        if source_info:
            source_mapping = config.get('storage.telegram.source_mapping', [])
            if source_mapping:
                source_name = source_info.get('name', '')
                source_id = source_info.get('id')
                
                logger.debug(f"Checking source mapping: source_name='{source_name}', source_id={source_id}, source_type={source_info.get('type')}")
                
                for mapping in source_mapping:
                    sources = mapping.get('sources', [])
                    channel_id = mapping.get('channel_id')
                    if channel_id and sources:
                        # æ£€æŸ¥åç§°åŒ¹é…
                        if source_name in sources:
                            logger.info(f"Channel determined by source mapping (name): {channel_id} (source: {source_name})")
                            return channel_id
                        
                        # æ£€æŸ¥IDåŒ¹é…ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                        if source_id:
                            for src in sources:
                                if isinstance(src, int):
                                    # ç›´æ¥åŒ¹é…
                                    if source_id == src:
                                        logger.info(f"Channel determined by source mapping (id): {channel_id} (source_id: {source_id})")
                                        return channel_id
                                    
                                    # å°è¯•-100æ ¼å¼è½¬æ¢åŒ¹é…
                                    # é…ç½®: -1003024714275, APIè¿”å›å¯èƒ½æ˜¯: -1003024714275 æˆ– 3024714275 æˆ– -3024714275
                                    src_str = str(src)
                                    source_id_str = str(source_id)
                                    
                                    # å»æ‰-100å‰ç¼€æ¯”è¾ƒ
                                    src_without_100 = src_str.replace('-100', '') if src_str.startswith('-100') else src_str
                                    source_without_100 = source_id_str.replace('-100', '') if source_id_str.startswith('-100') else source_id_str
                                    
                                    if src_without_100.lstrip('-') == source_without_100.lstrip('-'):
                                        logger.info(f"Channel determined by source mapping (id normalized): {channel_id} (config: {src}, actual: {source_id})")
                                        return channel_id
                
                logger.debug(f"No source mapping matched for source: {source_name or source_id}")
        
        # ä¼˜å…ˆçº§3: ä¸ªäººç›´å‘é…ç½®
        if is_direct_send:
            # é‡è¦ï¼šä¸è¦ç”¨config.getè·å–æ•´ä¸ªèŠ‚ç‚¹ï¼ˆä¼šç»•è¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
            # è€Œæ˜¯ç”¨å…·ä½“è·¯å¾„é€ä¸ªè·å–å€¼ï¼Œè¿™æ ·æ‰èƒ½è§¦å‘ç¯å¢ƒå˜é‡ä¼˜å…ˆæœºåˆ¶
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†ç›´å‘é…ç½®
            direct_enabled = config.get('storage.telegram.direct_send.channels.default') is not None
            
            if direct_enabled:
                # 1. ä¼˜å…ˆå°è¯•type_mappingæ˜ å°„ï¼ˆä»ç¯å¢ƒå˜é‡æ— æ³•é…ç½®dictï¼Œæ‰€ä»¥åªèƒ½ä»yamlè¯»å–ï¼‰
                direct_type_mapping = config._config.get('storage', {}).get('telegram', {}).get('direct_send', {}).get('type_mapping')
                if direct_type_mapping and isinstance(direct_type_mapping, dict):
                    channel_key = direct_type_mapping.get(content_type)
                    if channel_key:
                        # é€šè¿‡å…·ä½“è·¯å¾„è·å–é¢‘é“IDï¼ˆè§¦å‘ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
                        channel_id = config.get(f'storage.telegram.direct_send.channels.{channel_key}')
                        if channel_id:
                            logger.info(f"Channel determined by direct_send config: {channel_id} (type: {content_type} -> {channel_key})")
                            return channel_id
                
                # 2. ä½¿ç”¨defaulté¢‘é“ï¼ˆé€šè¿‡å…·ä½“è·¯å¾„è·å–ï¼Œè§¦å‘ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
                default_channel = config.get('storage.telegram.direct_send.channels.default')
                if default_channel:
                    logger.info(f"Channel determined by direct_send default: {default_channel}")
                    return default_channel
        
        # ä¼˜å…ˆçº§4å’Œ5: ä½¿ç”¨TelegramStorageçš„é»˜è®¤é€»è¾‘ï¼ˆç±»å‹æ˜ å°„+é»˜è®¤é¢‘é“ï¼‰
        # è¿”å›Noneè®©TelegramStorageè‡ªå·±å¤„ç†
        logger.debug(f"No specific channel rule matched, using TelegramStorage default logic")
        return None
    
    async def _store_link_pdf(
        self,
        analysis: Dict[str, Any],
        tags: List[str] = None,
        source_info: Dict[str, Any] = None,
        is_direct_send: bool = False,
        archive_id: Optional[int] = None
    ) -> Optional[str]:
        """
        å­˜å‚¨linkç±»å‹çš„PDFåˆ°documenté¢‘é“
        
        Args:
            analysis: Content analysis result (must contain web_archive_pdf)
            tags: æ ‡ç­¾åˆ—è¡¨
            source_info: æ¥æºä¿¡æ¯
            is_direct_send: æ˜¯å¦ä¸ºä¸ªäººç›´æ¥å‘é€
            
        Returns:
            Storage path or None
        """
        if not self.telegram_storage or not self.telegram_storage.is_available():
            logger.warning("Telegram storage not available for PDF")
            return None
        
        pdf_bytes = analysis.get('web_archive_pdf')
        if not pdf_bytes:
            logger.warning("No PDF bytes in analysis")
            return None
        
        try:
            import io
            from datetime import datetime
            import html
            
            # å‡†å¤‡PDFæ–‡ä»¶
            pdf_file = io.BytesIO(pdf_bytes)
            
            title = analysis.get('title', 'webpage')
            url = analysis.get('url', '')
            
            # è§£ç HTMLå®ä½“åå†ç”Ÿæˆæ–‡ä»¶å
            title_decoded = html.unescape(title)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåªä¿ç•™å®‰å…¨å­—ç¬¦ï¼‰
            safe_title = "".join(c for c in title_decoded[:50] if c.isalnum() or c in (' ', '-', '_', 'â€“', 'â€”')).strip()
            if not safe_title:
                safe_title = "webpage"
            
            file_name = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            pdf_file.name = file_name
            
            # ç¡®å®šç›®æ ‡é¢‘é“ï¼ˆdocumentç±»å‹ï¼‰
            # linkçš„PDFåº”è¯¥å­˜åˆ°documenté¢‘é“ï¼Œä¸æ˜¯texté¢‘é“
            target_channel_id = self._determine_channel_id(
                content_type='document',  # ä½¿ç”¨documentç±»å‹æ˜ å°„
                tags=tags,
                source_info=source_info,
                is_direct_send=is_direct_send
            )
            
            if not target_channel_id:
                # Fallbackåˆ°é»˜è®¤documenté¢‘é“
                config = get_config()
                target_channel_id = config.get('storage.telegram.channels.document')
            
            if not target_channel_id:
                logger.error("No document channel configured for PDF storage")
                return None
            
            # æ„å»ºcaption
            web_summary = analysis.get('web_archive_summary', '')
            # web_archive_summary å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
            if isinstance(web_summary, dict):
                summary = web_summary.get('text', '') or web_summary.get('summary', '')
            else:
                summary = str(web_summary) if web_summary else ''
            
            # è§£ç HTMLå®ä½“ï¼ˆå¦‚ &#8211; â†’ â€“ï¼‰
            import html
            title_decoded = html.unescape(title)
            url_decoded = html.unescape(url)
            summary_decoded = html.unescape(summary) if summary else ''
            
            caption_parts = [
                f"ğŸ”— ç½‘é¡µå­˜æ¡£ - {title_decoded}",
                f"\nğŸ“„ æ¥æº: {url_decoded}",
            ]
            
            if summary_decoded:
                # æˆªæ–­é•¿æ‘˜è¦
                summary_text = summary_decoded[:300] + "..." if len(summary_decoded) > 300 else summary_decoded
                caption_parts.append(f"\n\nğŸ“ æ‘˜è¦:\n{summary_text}")
            
            caption = "".join(caption_parts)
            
            # å‘é€PDF
            logger.info(f"Sending PDF to document channel {target_channel_id}: {file_name} ({len(pdf_bytes)} bytes)")
            
            # ç”ŸæˆæŒ‰é’®ï¼ˆå¦‚æœæœ‰archive_idï¼‰
            reply_markup = None
            if archive_id:
                # æŸ¥è¯¢æ˜¯å¦æœ‰ç¬”è®°ï¼ˆç”¨äºæŒ‰é’®çŠ¶æ€ï¼‰
                result = self.db_storage.db.execute(
                    "SELECT COUNT(*) as count FROM notes WHERE archive_id = ?",
                    (archive_id,)
                ).fetchone()
                has_notes = result['count'] > 0 if result else False
                
                # æŸ¥è¯¢ç²¾é€‰çŠ¶æ€
                fav_result = self.db_storage.db.execute(
                    "SELECT favorite FROM archives WHERE id = ?",
                    (archive_id,)
                ).fetchone()
                is_favorite = fav_result['favorite'] == 1 if fav_result else False
                
                # ç”ŸæˆæŒ‰é’®ï¼ˆå¤ç”¨telegram.pyçš„é€»è¾‘ï¼‰
                reply_markup = self.telegram_storage._create_archive_buttons(archive_id, has_notes, is_favorite)
            
            message = await self.telegram_storage.bot.send_document(
                chat_id=target_channel_id,
                document=pdf_file,
                caption=caption[:1024],  # Telegram captioné™åˆ¶
                filename=file_name,
                reply_markup=reply_markup
            )
            
            if message and message.document:
                storage_path = f"{target_channel_id}:{message.message_id}:{message.document.file_id}"
                logger.info(f"Link PDF stored successfully: {storage_path}")
                return storage_path
            else:
                logger.error("Failed to send PDF: no message returned")
                return None
                
        except Exception as e:
            logger.error(f"Error storing link PDF: {e}", exc_info=True)
            return None
    
    async def _store_to_telegram(
        self, 
        analysis: Dict[str, Any],
        tags: List[str] = None,
        source_info: Dict[str, Any] = None,
        is_direct_send: bool = False,
        archive_id: Optional[int] = None
    ) -> Optional[str]:
        """
        Store file to Telegram channel
        
        Args:
            analysis: Content analysis result
            tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆç”¨äºé¢‘é“é€‰æ‹©ï¼‰
            source_info: æ¥æºä¿¡æ¯ï¼ˆç”¨äºé¢‘é“é€‰æ‹©ï¼‰
            is_direct_send: æ˜¯å¦ä¸ºä¸ªäººç›´æ¥å‘é€
            
        Returns:
            Storage path or None
        """
        if not self.telegram_storage or not self.telegram_storage.is_available():
            logger.warning("Telegram storage not available")
            return None
        
        content_type = analysis.get('content_type')
        file_id = analysis.get('file_id')
        file_size = analysis.get('file_size', 0)
        
        # æ–‡æœ¬å’Œé“¾æ¥ç±»å‹ä¸éœ€è¦file_id
        if content_type not in ['text', 'link']:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not file_id:
                logger.error(f"No file_id in analysis for {content_type}")
                return None
        
        # ç¡®å®šå­˜å‚¨é¢‘é“ï¼ˆæ ¹æ®å¤šç§è§„åˆ™ï¼‰
        target_channel_id = self._determine_channel_id(
            content_type=content_type,
            tags=tags,
            source_info=source_info,
            is_direct_send=is_direct_send
        )
        
        # æ„å»ºmetadata
        # å¯¹äºåª’ä½“ç±»å‹ï¼ˆétext/linkï¼‰ï¼Œå¦‚æœcontentåŒ…å«æ¥æºä¿¡æ¯ï¼Œä½¿ç”¨å®ƒä½œä¸ºcaption
        # text/linkç±»å‹ï¼ŒcontentåŒ…å«å®Œæ•´çš„æ¥æºä¿¡æ¯å’Œæ­£æ–‡ï¼Œä¼šè¢«telegram.pyç‰¹æ®Šå¤„ç†
        # åª’ä½“ç±»å‹ï¼Œcontentå¯èƒ½åŒ…å« "æ¥æºä¿¡æ¯\nç”¨æˆ·caption"ï¼Œé€‚åˆä½œä¸ºcaptionæ˜¾ç¤º
        caption = None
        if content_type in ['text', 'link']:
            # text/linkç±»å‹ä¸éœ€è¦captionï¼Œä½¿ç”¨contentå­—æ®µ
            caption = None
        else:
            # åª’ä½“ç±»å‹ï¼šä¼˜å…ˆä½¿ç”¨contentï¼ˆå·²åŒ…å«æ¥æºä¿¡æ¯ï¼‰ï¼Œfallbackåˆ°title
            if analysis.get('content'):
                caption = analysis.get('content')
            elif analysis.get('title'):
                caption = analysis.get('title')
        
        metadata = {
            'file_id': file_id,
            'content_type': content_type,
            'title': analysis.get('title'),
            'content': analysis.get('content'),  # æ–‡æœ¬å’Œé“¾æ¥éœ€è¦contentå­—æ®µ
            'caption': caption,
            'file_size': file_size
        }
        
        # å¦‚æœç¡®å®šäº†ç‰¹å®šé¢‘é“ï¼Œæ·»åŠ override_channel_idå‚æ•°
        if target_channel_id:
            metadata['override_channel_id'] = target_channel_id
            logger.info(f"Using specific channel {target_channel_id} for this storage")
        
        logger.info(f"Forwarding {content_type} to Telegram channel: file_id={file_id[:20] if file_id else 'text/link'}..., size={format_file_size(file_size) if file_size else 'N/A'}")
        
        try:
            # æŸ¥è¯¢ç¬”è®°å’Œç²¾é€‰çŠ¶æ€ï¼ˆç”¨äºæŒ‰é’®ï¼‰
            has_notes = False
            is_favorite = False
            if archive_id:
                # æŸ¥è¯¢ç¬”è®°æ•°é‡
                result = self.db_storage.db.execute(
                    "SELECT COUNT(*) as count FROM notes WHERE archive_id = ?",
                    (archive_id,)
                ).fetchone()
                has_notes = result['count'] > 0 if result else False
                
                # æŸ¥è¯¢ç²¾é€‰çŠ¶æ€
                fav_result = self.db_storage.db.execute(
                    "SELECT favorite FROM archives WHERE id = ?",
                    (archive_id,)
                ).fetchone()
                is_favorite = fav_result['favorite'] == 1 if fav_result else False
            
            # å°†archive_idã€has_noteså’Œis_favoriteæ·»åŠ åˆ°metadata
            if archive_id:
                metadata['archive_id'] = archive_id
                metadata['has_notes'] = has_notes
                metadata['is_favorite'] = is_favorite
            
            storage_path = await self.telegram_storage.store(None, metadata)
            if storage_path:
                logger.info(f"Successfully stored to Telegram: {storage_path}")
            else:
                logger.error(f"Telegram storage returned None for {content_type}")
            return storage_path
        except Exception as e:
            logger.error(f"Exception during Telegram storage: {e}", exc_info=True)
            return None
    
    def _determine_storage_type(self, content_type: str, file_size: Optional[int]) -> str:
        """
        åŒå­˜å‚¨ç­–ç•¥ä¼˜åŒ–ï¼š
        - æ–‡æœ¬/é“¾æ¥ -> database + telegramé¢‘é“ï¼ˆåŒå­˜å‚¨ï¼Œæ•°æ®åº“ä¸ºä¸»ï¼Œé¢‘é“ä¸ºè¾…åŠ©æµè§ˆï¼‰
        - åª’ä½“æ–‡ä»¶ (<2GB) -> telegramé¢‘é“ (file_idæ°¸ä¹…æœ‰æ•ˆ)
        - è¶…å¤§æ–‡ä»¶ (>2GB) -> reference (ä»…å­˜å‚¨å…ƒæ•°æ®)
        
        Args:
            content_type: Content type
            file_size: File size in bytes
            
        Returns:
            Storage type (è¿”å›STORAGE_TELEGRAMè¡¨ç¤ºéœ€è¦å­˜å‚¨åˆ°é¢‘é“)
        """
        # æ–‡æœ¬å’Œé“¾æ¥ï¼šåŒæ—¶å­˜æ•°æ®åº“+é¢‘é“ï¼ˆä½†æ ‡è®°ä¸ºSTORAGE_TELEGRAMè®©å…¶å‘é€åˆ°é¢‘é“ï¼‰
        # æ•°æ®åº“å­˜å‚¨åœ¨archive_contentä¸­ä¼šè‡ªåŠ¨è¿›è¡Œ
        if content_type in ['text', 'link']:
            if self.telegram_storage and self.telegram_storage.is_available():
                logger.debug(f"{content_type} -> database + telegram (dual storage)")
                return STORAGE_TELEGRAM  # è¿”å›TELEGRAMè¡¨ç¤ºéœ€è¦å‘é€åˆ°é¢‘é“
            else:
                logger.debug(f"{content_type} -> database only (telegram unavailable)")
                return STORAGE_DATABASE
        
        # contactå’Œlocationä»ç„¶åªå­˜æ•°æ®åº“
        if content_type in ['contact', 'location']:
            return STORAGE_DATABASE
        
        # æ— æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼Œå­˜ä¸ºå¼•ç”¨
        if file_size is None:
            logger.warning(f"{content_type} -> reference (no file size)")
            return STORAGE_REFERENCE
        
        # Telegramé¢‘é“æ”¯æŒ2GBå†…çš„æ‰€æœ‰æ–‡ä»¶
        if file_size < TELEGRAM_MAX_SIZE:
            if self.telegram_storage and self.telegram_storage.is_available():
                logger.debug(f"{content_type} ({format_file_size(file_size)}) -> telegram")
                return STORAGE_TELEGRAM
            else:
                logger.warning(f"Telegramä¸å¯ç”¨ï¼Œé™çº§ä¸ºå¼•ç”¨")
                return STORAGE_REFERENCE
        
        # è¶…è¿‡2GBï¼Œåªèƒ½å­˜å¼•ç”¨
        logger.warning(f"{content_type} ({format_file_size(file_size)}) è¶…è¿‡2GB -> reference")
        return STORAGE_REFERENCE
    
    def search_archives(
        self,
        keyword: Optional[str] = None,
        content_type: Optional[str] = None,
        tag_names: Optional[list] = None,
        limit: int = 10
    ) -> list:
        """
        Search archives
        
        Args:
            keyword: Search keyword
            content_type: Filter by content type
            tag_names: Filter by tag names
            limit: Maximum results
            
        Returns:
            List of archive dictionaries
        """
        return self.db_storage.search_archives(
            keyword=keyword,
            content_type=content_type,
            tag_names=tag_names,
            limit=limit
        )
    
    def get_archive(self, archive_id: int) -> Optional[Dict[str, Any]]:
        """
        Get archive by ID
        
        Args:
            archive_id: Archive ID
            
        Returns:
            Archive dictionary or None
        """
        return self.db_storage.get_archive(archive_id)
    
    def delete_archive(self, archive_id: int) -> bool:
        """
        Delete archive
        
        Args:
            archive_id: Archive ID
            
        Returns:
            True if deleted, False otherwise
        """
        return self.db_storage.delete_archive(archive_id)
