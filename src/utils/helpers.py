"""
Helper utility functions
"""

import html
import logging
import re
from datetime import datetime
from typing import List, Optional
from urllib.parse import urlparse
from .config import get_config

logger = logging.getLogger(__name__)


def escape_html(text: str) -> str:
    """
    è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢HTMLæ³¨å…¥
    
    ç»Ÿä¸€çš„HTMLè½¬ä¹‰å‡½æ•°ï¼Œç”¨äºæ‰€æœ‰éœ€è¦åœ¨Telegram HTMLæ¶ˆæ¯ä¸­æ˜¾ç¤ºçš„ç”¨æˆ·è¾“å…¥æ–‡æœ¬ã€‚
    
    Args:
        text: éœ€è¦è½¬ä¹‰çš„æ–‡æœ¬
        
    Returns:
        è½¬ä¹‰åçš„å®‰å…¨HTMLæ–‡æœ¬
        
    Examples:
        >>> escape_html("A<B>&C")
        'A&lt;B&gt;&amp;C'
        >>> escape_html("æ­£å¸¸æ–‡æœ¬")
        'æ­£å¸¸æ–‡æœ¬'
    """
    if not text:
        return text
    return html.escape(str(text))


def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human-readable format
    
    Args:
        size_bytes: File size in bytes
        
    Returns:
        Formatted string (e.g., "1.5 MB")
    """
    if size_bytes == 0:
        return "0 B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and unit_index < len(units) - 1:
        size /= 1024.0
        unit_index += 1
    
    if unit_index == 0:
        return f"{int(size)} {units[unit_index]}"
    else:
        return f"{size:.2f} {units[unit_index]}"


def format_source_header(message, source_info: Optional[dict] = None) -> str:
    """
    æ ¼å¼åŒ–æ¶ˆæ¯æ¥æºä¿¡æ¯å¤´éƒ¨
    
    Args:
        message: Telegram Messageå¯¹è±¡
        source_info: æ¥æºä¿¡æ¯ {'name': str, 'id': int, 'type': str}
        
    Returns:
        æ ¼å¼åŒ–çš„æ¥æºä¿¡æ¯å­—ç¬¦ä¸²
        - è½¬å‘æ¶ˆæ¯: "æ¥æº <a href='é“¾æ¥'>é¢‘é“å</a> | æ—¥æœŸ 2026-02-01 10:30\n--------------------"
        - ç›´å‘æ¶ˆæ¯: "[å­˜æ¡£]  |  æ—¥æœŸ 2026-02-01 10:30\n--------------------"
    """
    from telegram import MessageOriginChannel, MessageOriginChat
    
    # è·å–æ¶ˆæ¯æ—¥æœŸ
    msg_date = message.date
    date_str = msg_date.strftime("%Y-%m-%d %H:%M")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºè½¬å‘æ¶ˆæ¯
    if not message.forward_origin or not source_info:
        return f"[å­˜æ¡£]  |  æ—¥æœŸ {date_str}\n--------------------"
    
    # è·å–è½¬å‘æ—¥æœŸï¼ˆè½¬å‘æ¶ˆæ¯ä½¿ç”¨åŸå§‹æ¶ˆæ¯æ—¥æœŸï¼‰
    forward_date = message.forward_origin.date
    date_str = forward_date.strftime("%Y-%m-%d %H:%M")
    
    # è·å–æ¥æºåç§°
    source_name = source_info.get('name', 'æœªçŸ¥')
    
    # æ ¼å¼åŒ–æ¥æºä¿¡æ¯ï¼ˆçº¯æ–‡æœ¬ï¼Œä¸ä½¿ç”¨é“¾æ¥ï¼‰
    return f"æ¥æº {escape_html(source_name)}  |  æ—¥æœŸ {date_str}\n--------------------"


def extract_hashtags(text: str) -> List[str]:
    """
    Extract hashtags from text
    
    Args:
        text: Input text
        
    Returns:
        List of hashtags (without # symbol)
    """
    if not text:
        return []
    
    # Match hashtags (support English, Chinese, numbers, underscore)
    pattern = r'#([\w\u4e00-\u9fa5]+)'
    matches = re.findall(pattern, text)
    
    # Remove duplicates while preserving order
    seen = set()
    unique_tags = []
    for tag in matches:
        tag_lower = tag.lower()
        if tag_lower not in seen:
            seen.add(tag_lower)
            unique_tags.append(tag)
    
    return unique_tags


def should_create_note(content: str) -> tuple:
    """
    åˆ¤æ–­å†…å®¹æ˜¯å¦åº”è¯¥åˆ›å»ºç¬”è®°ä»¥åŠç¬”è®°ç±»å‹
    
    Args:
        content: è¾“å…¥å†…å®¹
        
    Returns:
        (is_short_note, note_type)
        - is_short_note: True=ç›´æ¥ä½œä¸ºç¬”è®°ï¼ˆä¸å½’æ¡£ï¼‰ï¼ŒFalse=å½’æ¡£å¹¶å¯èƒ½ç”ŸæˆAIç¬”è®°
        - note_type: 'short'ï¼ˆçŸ­æ–‡æœ¬ï¼‰| 'long'ï¼ˆé•¿æ–‡æœ¬ï¼‰| 'none'ï¼ˆç©ºå†…å®¹ï¼‰
    """
    if not content:
        return False, 'none'
    
    # ä»é…ç½®è·å–é˜ˆå€¼
    config = get_config()
    ai_config = config.get('ai', {})
    text_thresholds = ai_config.get('text_thresholds', {})
    
    # æ£€æµ‹ä¸­è‹±æ–‡å­—ç¬¦
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
    english_chars = len(re.findall(r'[a-zA-Z]', content))
    
    # åˆ¤æ–­é˜ˆå€¼ï¼ˆèŠå¤©å‹å¥½å‹ï¼‰
    if chinese_chars > english_chars:
        # ä¸­æ–‡ä¸ºä¸»
        threshold = int(text_thresholds.get('note_chinese', 150))
    else:
        # è‹±æ–‡ä¸ºä¸»
        threshold = int(text_thresholds.get('note_english', 250))
    
    char_count = len(content)
    
    if char_count < threshold:
        return True, 'short'  # çŸ­æ–‡æœ¬ï¼Œç›´æ¥ä½œä¸ºç¬”è®°
    else:
        return False, 'long'  # é•¿æ–‡æœ¬ï¼Œéœ€è¦å½’æ¡£å¹¶å¯èƒ½ç”ŸæˆAIç¬”è®°


def is_url(text: str) -> bool:
    """
    Check if text is a URL
    
    Args:
        text: Input text
        
    Returns:
        True if text is a URL, False otherwise
    """
    if not text:
        return False
    
    try:
        result = urlparse(text.strip())
        return all([result.scheme, result.netloc])
    except Exception:
        return False


def extract_urls(text: str) -> List[str]:
    """
    Extract URLs from text
    
    Args:
        text: Input text
        
    Returns:
        List of URLs
    """
    if not text:
        return []
    
    # URL pattern
    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    urls = re.findall(url_pattern, text)
    
    return urls


def remove_forward_signature(text: Optional[str], source_name: Optional[str]) -> Optional[str]:
    """
    ç§»é™¤è½¬å‘æ¶ˆæ¯ä¸­çš„æ¥æºç­¾åè¡Œï¼ˆå¦‚â€œé¢‘é“å + URLâ€å°¾éƒ¨ç­¾åï¼‰
    
    ä»…åœ¨æ£€æµ‹åˆ°å°¾éƒ¨ä¸¤è¡Œåˆ†åˆ«ä¸ºæ¥æºåç§°å’ŒURLæ—¶ç§»é™¤ã€‚
    """
    if not text or not source_name:
        return text
    
    lines = [line.rstrip() for line in str(text).splitlines()]
    # å»æ‰å°¾éƒ¨ç©ºè¡Œ
    while lines and not lines[-1].strip():
        lines.pop()
    
    if len(lines) < 2:
        return text
    
    last_line = lines[-1].strip()
    prev_line = lines[-2].strip()
    
    if prev_line == source_name and is_url(last_line):
        lines = lines[:-2]
        while lines and not lines[-1].strip():
            lines.pop()
        return "\n".join(lines).strip() if lines else None
    
    return text


def extract_user_comment_from_merged(
    merged_caption: Optional[str],
    original_caption: Optional[str]
) -> Optional[str]:
    """
    ä»åˆå¹¶çš„captionä¸­æå–ç”¨æˆ·è¯„è®ºéƒ¨åˆ†ï¼Œé¿å…ä¸åŸå§‹captioné‡å¤
    """
    if not merged_caption:
        return None
    
    merged = str(merged_caption).strip()
    if not merged:
        return None
    
    original = str(original_caption).strip() if original_caption else ''
    if original:
        if merged == original:
            return None
        # ç§»é™¤åŸå§‹captionå†…å®¹
        pattern = re.escape(original)
        cleaned = re.sub(rf"(?:^|\n+)({pattern})(?:\n+|$)", "\n", merged)
        cleaned = re.sub(r"\n{3,}", "\n\n", cleaned).strip()
        return cleaned or None
    
    return merged


def truncate_text(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate text to max length
    
    Args:
        text: Input text
        max_length: Maximum length
        suffix: Suffix to add if truncated
        
    Returns:
        Truncated text
    """
    if not text or len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix


async def smart_sort_messages(messages: List[tuple], ai_summarizer=None) -> List[tuple]:
    """
    æ™ºèƒ½æ’åºæ¶ˆæ¯åˆ—è¡¨ï¼ˆå¤„ç†Telegramè‡ªåŠ¨åˆ†ç‰‡å¯èƒ½å¯¼è‡´çš„ä¹±åºï¼‰
    
    æ¶ˆæ¯æ ¼å¼ï¼š[(timestamp, message_id, text), ...]
    
    ç­–ç•¥ï¼š
    1. å¦‚æœæ¶ˆæ¯æ•°é‡<=2ï¼ŒæŒ‰message_idæ’åºï¼ˆç®€å•åœºæ™¯ï¼‰
    2. å¦‚æœæ¶ˆæ¯æ•°é‡>2ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨é•¿åº¦å·®å¼‚>3000çš„æƒ…å†µ
       - å­˜åœ¨ï¼šæŒ‰é•¿åº¦é™åºæ’åˆ—ï¼ˆé•¿æ¶ˆæ¯åœ¨å‰ï¼‰
       - ä¸å­˜åœ¨ï¼šæŒ‰message_idæ’åºï¼ˆæ—¶é—´é¡ºåºï¼‰
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ [(timestamp, message_id, text), ...]
        ai_summarizer: AIæ€»ç»“å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºæœªæ¥AIæ’åºä¼˜åŒ–ï¼‰
        
    Returns:
        æ’åºåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if not messages:
        return []
    
    if len(messages) <= 2:
        # ç®€å•åœºæ™¯ï¼šç›´æ¥æŒ‰message_idæ’åº
        return sorted(messages, key=lambda x: x[1])
    
    # å¤æ‚åœºæ™¯ï¼šæ£€æŸ¥é•¿åº¦å·®å¼‚
    lengths = [len(msg[2]) for msg in messages]
    max_len = max(lengths)
    min_len = min(lengths)
    length_diff = max_len - min_len
    
    if length_diff > 3000:
        # å­˜åœ¨æ˜¾è‘—é•¿åº¦å·®å¼‚ï¼ŒæŒ‰é•¿åº¦é™åºï¼ˆé•¿æ¶ˆæ¯å¯èƒ½æ˜¯ä¸»ä½“ï¼‰
        sorted_msgs = sorted(messages, key=lambda x: len(x[2]), reverse=True)
        logger.info(f"Sorted by length (diff={length_diff}): {[len(m[2]) for m in sorted_msgs]}")
        return sorted_msgs
    else:
        # é•¿åº¦ç›¸è¿‘ï¼ŒæŒ‰message_idæ’åºï¼ˆæ—¶é—´é¡ºåºï¼‰
        sorted_msgs = sorted(messages, key=lambda x: x[1])
        logger.info(f"Smart sorted {len(messages)} messages into {len(sorted_msgs)} groups")
        return sorted_msgs


def split_long_message(text: str, max_length: int = 4096, preserve_newlines: bool = True) -> List[str]:
    """
    æ™ºèƒ½åˆ†å‰²è¶…é•¿æ¶ˆæ¯ä¸ºå¤šæ¡æ¶ˆæ¯ï¼ˆTelegramå•æ¡æ¶ˆæ¯é™åˆ¶4096å­—ç¬¦ï¼‰
    
    Args:
        text: è¦åˆ†å‰²çš„æ–‡æœ¬
        max_length: å•æ¡æ¶ˆæ¯æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤4096ï¼‰
        preserve_newlines: æ˜¯å¦åœ¨æ®µè½è¾¹ç•Œåˆ†å‰²ï¼ˆä¼˜å…ˆåœ¨\\n\\nå¤„åˆ†å‰²ï¼‰
        
    Returns:
        åˆ†å‰²åçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if not text or len(text) <= max_length:
        return [text] if text else []
    
    parts = []
    remaining = text
    
    while remaining:
        if len(remaining) <= max_length:
            # å‰©ä½™å†…å®¹å°äºé™åˆ¶ï¼Œç›´æ¥æ·»åŠ 
            parts.append(remaining)
            break
        
        # å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹
        split_pos = max_length
        
        if preserve_newlines:
            # ä¼˜å…ˆåœ¨æ®µè½è¾¹ç•Œï¼ˆ\\n\\nï¼‰åˆ†å‰²
            last_paragraph = remaining[:max_length].rfind('\\n\\n')
            if last_paragraph > max_length * 0.7:  # å¦‚æœæ®µè½è¾¹ç•Œåœ¨70%ä¹‹åï¼Œä½¿ç”¨å®ƒ
                split_pos = last_paragraph + 2  # +2 åŒ…å«\\n\\n
            else:
                # å…¶æ¬¡åœ¨å•ä¸ªæ¢è¡Œç¬¦å¤„åˆ†å‰²
                last_newline = remaining[:max_length].rfind('\\n')
                if last_newline > max_length * 0.7:
                    split_pos = last_newline + 1  # +1 åŒ…å«\\n
                else:
                    # æœ€ååœ¨ç©ºæ ¼å¤„åˆ†å‰²
                    last_space = remaining[:max_length].rfind(' ')
                    if last_space > max_length * 0.7:
                        split_pos = last_space + 1  # +1 åŒ…å«ç©ºæ ¼
        
        # åˆ†å‰²å¹¶æ·»åŠ åˆ°åˆ—è¡¨
        parts.append(remaining[:split_pos])
        remaining = remaining[split_pos:]
    
    logger.debug(f"Split long message into {len(parts)} parts (original length: {len(text)})")
    return parts


async def smart_sort_messages(messages: List[tuple], ai_summarizer=None) -> List[tuple]:
    """
    æ™ºèƒ½æ’åºæ¶ˆæ¯ï¼ˆå¤„ç†Telegramåˆ†ç‰‡æ¶ˆæ¯å¯èƒ½ä¹±åºçš„é—®é¢˜ï¼‰
    
    Args:
        messages: [(timestamp, message_id, text), ...] æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        ai_summarizer: AI summarizerå®ä¾‹ï¼ˆç”¨äºåˆ†ææ–‡æœ¬é¡ºåºï¼‰
        
    Returns:
        æ’åºåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if len(messages) <= 1:
        return messages
    
    # æ£€æµ‹æ—¶é—´çª—å£ï¼ˆ1ç§’å†…ï¼‰åŒæ—¶åˆ°è¾¾çš„æ¶ˆæ¯ç»„
    TIME_WINDOW = 1.0  # ç§’
    groups = []
    current_group = [messages[0]]
    
    for i in range(1, len(messages)):
        time_diff = messages[i][0] - current_group[-1][0]  # timestampå·®å¼‚
        if time_diff <= TIME_WINDOW:
            current_group.append(messages[i])
        else:
            groups.append(current_group)
            current_group = [messages[i]]
    
    if current_group:
        groups.append(current_group)
    
    # å¯¹æ¯ä¸ªç»„è¿›è¡Œæ™ºèƒ½æ’åº
    sorted_messages = []
    for group in groups:
        if len(group) == 1:
            sorted_messages.extend(group)
        else:
            # å¤šæ¡æ¶ˆæ¯éœ€è¦æ™ºèƒ½æ’åº
            sorted_group = await _smart_sort_group(group, ai_summarizer)
            sorted_messages.extend(sorted_group)
    
    logger.info(f"Smart sorted {len(messages)} messages into {len(groups)} groups")
    return sorted_messages


async def _smart_sort_group(group: List[tuple], ai_summarizer) -> List[tuple]:
    """
    æ™ºèƒ½æ’åºä¸€ç»„åŒæ—¶åˆ°è¾¾çš„æ¶ˆæ¯
    
    ç­–ç•¥ï¼š
    1. å¦‚æœé•¿åº¦å·®å¼‚æ˜æ˜¾ï¼ˆ>500å­—ç¬¦ï¼‰ï¼Œé•¿çš„åœ¨å‰ï¼ˆæ¥è¿‘4096çš„å…ˆå‘ï¼‰
    2. å¦‚æœé•¿åº¦ç›¸è¿‘ï¼Œä½¿ç”¨AIåˆ†æé¦–å°¾50å­—ç¬¦åˆ¤æ–­é¡ºåº
    
    Args:
        group: æ¶ˆæ¯ç»„
        ai_summarizer: AI summarizerå®ä¾‹
        
    Returns:
        æ’åºåçš„æ¶ˆæ¯ç»„
    """
    if len(group) <= 1:
        return group
    
    # æå–æ–‡æœ¬é•¿åº¦
    lengths = [(i, len(msg[2])) for i, msg in enumerate(group)]
    
    # æ£€æŸ¥é•¿åº¦å·®å¼‚
    max_length = max(lengths, key=lambda x: x[1])[1]
    min_length = min(lengths, key=lambda x: x[1])[1]
    length_diff = max_length - min_length
    
    LENGTH_THRESHOLD = 500  # é•¿åº¦å·®å¼‚é˜ˆå€¼
    
    # æƒ…å†µ1ï¼šé•¿åº¦å·®å¼‚æ˜æ˜¾ -> é•¿çš„åœ¨å‰ï¼ˆæ¥è¿‘4096çš„ï¼‰
    if length_diff > LENGTH_THRESHOLD:
        # æŒ‰é•¿åº¦é™åºæ’åˆ—ï¼ˆé•¿çš„åœ¨å‰ï¼‰
        sorted_indices = sorted(range(len(group)), key=lambda i: len(group[i][2]), reverse=True)
        sorted_group = [group[i] for i in sorted_indices]
        logger.info(f"Sorted by length (diff={length_diff}): {[len(m[2]) for m in sorted_group]}")
        return sorted_group
    
    # æƒ…å†µ2ï¼šé•¿åº¦ç›¸è¿‘ -> ä½¿ç”¨AIåˆ†æ
    if ai_summarizer and ai_summarizer.is_available() and len(group) == 2:
        try:
            # æå–é¦–å°¾50å­—ç¬¦
            msg1_text = group[0][2]
            msg2_text = group[1][2]
            
            msg1_sample = msg1_text[:50] + "..." + msg1_text[-50:] if len(msg1_text) > 100 else msg1_text
            msg2_sample = msg2_text[:50] + "..." + msg2_text[-50:] if len(msg2_text) > 100 else msg2_text
            
            # æ„é€ AIåˆ¤æ–­prompt
            prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤æ®µæ–‡æœ¬çš„å…ˆåé¡ºåºã€‚æ¯æ®µæ–‡æœ¬æ˜¾ç¤ºäº†å¼€å¤´å’Œç»“å°¾éƒ¨åˆ†ã€‚

æ–‡æœ¬Aï¼ˆé•¿åº¦{len(msg1_text)}å­—ç¬¦ï¼‰ï¼š
{msg1_sample}

æ–‡æœ¬Bï¼ˆé•¿åº¦{len(msg2_text)}å­—ç¬¦ï¼‰ï¼š
{msg2_sample}

è¯·åˆ†æï¼šå¦‚æœè¿™æ˜¯ä¸€æ®µè¢«åˆ†å‰²çš„é•¿æ–‡æœ¬ï¼Œå“ªç§é¡ºåºæ›´åˆç†ï¼Ÿ
1. Aåœ¨å‰Båœ¨å
2. Båœ¨å‰Aåœ¨å

è¯·åªå›ç­”æ•°å­—1æˆ–2ï¼Œä¸è¦è§£é‡Šã€‚"""

            # è°ƒç”¨AI
            result = await ai_summarizer.summarize_content(
                content=prompt,
                content_type='text_order_analysis',
                max_tokens=10,
                language='zh-CN'
            )
            
            if result and result.get('success'):
                answer = result.get('summary', '').strip()
                if '2' in answer or 'Båœ¨å‰' in answer or 'BA' in answer:
                    # Båœ¨å‰Aåœ¨åï¼Œéœ€è¦äº¤æ¢
                    logger.info(f"AI determined order: B-A (reversed)")
                    return [group[1], group[0]]
                else:
                    # Aåœ¨å‰Båœ¨åï¼Œä¿æŒåŸåº
                    logger.info(f"AI determined order: A-B (original)")
                    return group
        except Exception as e:
            logger.warning(f"AI order analysis failed: {e}")
    
    # é™çº§ï¼šæŒ‰message_idæ’åºï¼ˆTelegramä¿è¯é€’å¢ï¼‰
    sorted_group = sorted(group, key=lambda x: x[1])  # x[1] is message_id
    logger.info(f"Sorted by message_id (fallback)")
    return sorted_group


def format_datetime(dt: Optional[datetime] = None, format_str: str = "%Y-%m-%d %H:%M:%S") -> str:
    """
    Format datetime object
    
    Args:
        dt: Datetime object (if None, use current time)
        format_str: Format string
        
    Returns:
        Formatted datetime string
    """
    if dt is None:
        dt = datetime.now()
    elif isinstance(dt, str):
        try:
            dt = datetime.fromisoformat(dt)
        except ValueError:
            return dt
    
    return dt.strftime(format_str)


def parse_datetime(dt_str: str) -> Optional[datetime]:
    """
    Parse datetime string
    
    Args:
        dt_str: Datetime string
        
    Returns:
        Datetime object or None if parsing failed
    """
    if not dt_str:
        return None
    
    try:
        return datetime.fromisoformat(dt_str)
    except ValueError:
        logger.warning(f"Failed to parse datetime: {dt_str}")
        return None


def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename by removing invalid characters
    
    Args:
        filename: Original filename
        
    Returns:
        Sanitized filename
    """
    if not filename:
        return "untitled"
    
    # Remove invalid characters
    invalid_chars = r'[<>:"/\\|?*]'
    sanitized = re.sub(invalid_chars, '_', filename)
    
    # Limit length
    max_length = 255
    if len(sanitized) > max_length:
        name, ext = splitext(sanitized)
        if len(ext) > 10:
            ext = ext[:10]
        max_name_length = max_length - len(ext)
        sanitized = name[:max_name_length] + ext
    
    return sanitized


def splitext(filename: str) -> tuple:
    """
    Split filename into name and extension
    
    Args:
        filename: Filename
        
    Returns:
        Tuple of (name, extension)
    """
    if '.' in filename:
        parts = filename.rsplit('.', 1)
        return parts[0], '.' + parts[1]
    return filename, ''


def escape_markdown(text: str) -> str:
    """
    Escape special characters for Telegram MarkdownV2
    
    Args:
        text: Input text
        
    Returns:
        Escaped text
    """
    if not text:
        return ""
    
    # Characters that need to be escaped in MarkdownV2
    special_chars = r'_*[]()~`>#+-=|{}.!'
    
    escaped = text
    for char in special_chars:
        escaped = escaped.replace(char, '\\' + char)
    
    return escaped


def validate_telegram_id(telegram_id: int) -> bool:
    """
    Validate Telegram user/chat ID
    
    Args:
        telegram_id: Telegram ID
        
    Returns:
        True if valid, False otherwise
    """
    # Telegram IDs are positive integers for users
    # Negative integers for groups/channels
    # Must be non-zero
    return telegram_id != 0 and isinstance(telegram_id, int)


def get_content_type_emoji(content_type: str) -> str:
    """
    Get emoji for content type
    
    Args:
        content_type: Content type
        
    Returns:
        Emoji string
    """
    emoji_map = {
        'text': 'ğŸ“',
        'image': 'ğŸ–¼ï¸',
        'video': 'ğŸ¬',
        'document': 'ğŸ“„',
        'link': 'ğŸ”—',
        'audio': 'ğŸµ',
        'voice': 'ğŸ¤',
        'sticker': 'ğŸ¨',
        'animation': 'ğŸï¸',
        'contact': 'ğŸ‘¤',
        'location': 'ğŸ“',
    }
    
    return emoji_map.get(content_type, 'ğŸ“¦')


async def send_or_update_reply(update, context, text, command_name, **kwargs):
    """
    Send a reply message or update existing one if found
    Delete old command reply and send new one to keep chat clean
    
    Args:
        update: Telegram update
        context: Bot context
        text: Message text
        command_name: Command name (e.g., 'backup', 'stats')
        **kwargs: Additional arguments for send_message/reply_text
        
    Returns:
        Sent message object
    """
    from telegram.error import BadRequest
    
    # Get user_id and chat_id
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    
    # Use bot_data for persistence across sessions, keyed by user_id and command
    reply_key = f'last_reply_{user_id}_{command_name}'
    
    # Try to delete old reply if exists
    old_data = context.bot_data.get(reply_key)
    if old_data and isinstance(old_data, dict):
        old_message_id = old_data.get('message_id')
        old_chat_id = old_data.get('chat_id')
        
        if old_message_id and old_chat_id:
            try:
                await context.bot.delete_message(
                    chat_id=old_chat_id,
                    message_id=old_message_id
                )
                logger.info(f"ğŸ—‘ï¸ Deleted old reply for /{command_name} (msg_id: {old_message_id})")
            except BadRequest as e:
                # Message might be already deleted or too old
                logger.debug(f"Could not delete old reply for /{command_name}: {e}")
            except Exception as e:
                logger.warning(f"Error deleting old reply for /{command_name}: {e}")
    
    # Send new reply
    if hasattr(update, 'message') and update.message:
        sent_message = await update.message.reply_text(text, **kwargs)
    else:
        sent_message = await context.bot.send_message(
            chat_id=chat_id,
            text=text,
            **kwargs
        )
    
    # Store new message_id and chat_id in bot_data for persistence
    context.bot_data[reply_key] = {
        'message_id': sent_message.message_id,
        'chat_id': chat_id,
        'command': command_name,
        'timestamp': sent_message.date.timestamp() if sent_message.date else None
    }
    
    logger.info(f"ğŸ“ Stored reply for /{command_name} (msg_id: {sent_message.message_id})")
    
    return sent_message
